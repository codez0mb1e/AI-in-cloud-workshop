{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Pipelines\n",
    "\n",
    "Цель лабораторной работы: \n",
    "\n",
    "- создание с __Конвейеров машинного обучения__ (ML Pipelines) в Azure ML\n",
    "- тренировка модели машинного обучения.\n",
    "\n",
    "## Подготовка \n",
    "\n",
    "Импорт необходимых модулей и проверка версии AzureML SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Environment, Experiment, Model\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "# Check core SDK version number\n",
    "print(f'SDK version: {azureml.core.VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим конфигурацию эксперимента: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment pipeline-experiment was initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'pipeline-experiment',\n",
       " 'working_subdir': 'pipeline-experiment-lab',\n",
       " 'environment_name': 'environments-experiment',\n",
       " 'core': {'expriments_root_dir': 'experiments/',\n",
       "  'datastore_name': 'aml_ws_datastore_v2',\n",
       "  'dataset_name': 'diabetes-data',\n",
       "  'ml_cluster_name': 'aml-ws-cluster',\n",
       "  'ml_model_name': 'diabetes-predict-model'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run core.py\n",
    "\n",
    "config = get_experiment_config('lab_6A')\n",
    "init_experiment(config)\n",
    "experiment_dir = get_experiment_dir(config)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Соединение со Azure ML Workspace\n",
    "\n",
    "Устанавливаем соединение с Рабочей областью в Azure ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Workspace: aml-workshop.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(f'Successfully connected to Workspace: {ws.name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зададим Шаги ML Конвейера\n",
    "\n",
    "Зададим и сохраним скрипт для Шага регистрации модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/register_model.py\n",
    "\n",
    "#%% Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "\n",
    "#%% Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir', type=str, dest='model_dir', default='outputs', help='Define ML model directory')\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "#%% Set model directory\n",
    "model_dir = args.model_dir\n",
    "\n",
    "\n",
    "#%% Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "#%% Load the model\n",
    "model_path = f'{model_dir}/model.pkl'\n",
    "\n",
    "print(f'Loading {model_path}...')\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "#%% Register model\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path=model_path,\n",
    "               model_name='diabetes-predict-model',\n",
    "               tags={'Lab': '5A'})\n",
    "\n",
    "#%% Finish Experiment\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим и запустим ML Конвейер\n",
    "\n",
    "Подготовка к созданию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dataset diabetes-data: Diabetes Disease Database\n",
      "Environment environments-experiment will be used.\n",
      "ML cluster contains 1 compute nodes in Steady state\n"
     ]
    }
   ],
   "source": [
    "# Get dataset\n",
    "data_ds = ws.datasets.get(config['core']['dataset_name'])\n",
    "print(f'Used dataset {data_ds.name}: {data_ds.description}')\n",
    "\n",
    "# Get environment\n",
    "env = Environment.get(ws, config['environment_name'])\n",
    "print(f'Environment {env.name} will be used.')\n",
    "\n",
    "# Get compute cluster\n",
    "cluster = ComputeTarget(workspace=ws, name=config['core']['ml_cluster_name'])\n",
    "cluster_state = cluster.get_status()\n",
    "print(f'ML cluster contains {cluster_state.current_node_count} compute nodes in {cluster_state.allocation_state} state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируем необходимые скрипты в директорию Эксперимента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register_model.py  train_model.py\n"
     ]
    }
   ],
   "source": [
    "!cp scripts/train_model.py $experiment_dir\n",
    "!cp scripts/register_model.py $experiment_dir\n",
    "!ls $experiment_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение Шагов ML Конвейера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If environment_definition or conda_dependencies_file_path is specified, Azure ML will not install any framework related packages on behalf of the user.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps were completely defined.\n"
     ]
    }
   ],
   "source": [
    "## Import packages related with Azure ML Pipeline \n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "\n",
    "## Step 0: Prepare\n",
    "# Set Pipeline Run Configuration\n",
    "pipeline_run_config = RunConfiguration()\n",
    "pipeline_run_config.target = cluster\n",
    "pipeline_run_config.environment = env\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_dir = PipelineData('model_dir', datastore=ws.get_default_datastore())\n",
    "\n",
    "\n",
    "## Step 1: Train model\n",
    "estimator = SKLearn(source_directory=experiment_dir,\n",
    "                    compute_target=cluster,\n",
    "                    environment_definition=pipeline_run_config.environment,\n",
    "                    entry_script='train_model.py')\n",
    "\n",
    "\n",
    "train_model_step = EstimatorStep(name='Train Model Step',\n",
    "                                 estimator=estimator, \n",
    "                                 estimator_entry_script_arguments=['--output_dir', model_dir],\n",
    "                                 inputs=[data_ds.as_named_input('data')],\n",
    "                                 outputs=[model_dir],\n",
    "                                 compute_target=cluster,\n",
    "                                 allow_reuse=True)\n",
    "\n",
    "## Step 2: Register trained model\n",
    "register_model_step = PythonScriptStep(name='Register Model Step',\n",
    "                                       source_directory=experiment_dir,\n",
    "                                       script_name='register_model.py',\n",
    "                                       arguments=['--model_dir', model_dir],\n",
    "                                       inputs=[model_dir],\n",
    "                                       compute_target=cluster,\n",
    "                                       runconfig=pipeline_run_config,\n",
    "                                       allow_reuse=True)\n",
    "\n",
    "## Complete\n",
    "print('Pipeline steps were completely defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск созданного ML-конвейера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the pipeline\n",
    "pipeline_steps = [train_model_step, register_model_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline was built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name=config['experiment_name'])\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Перейдети по ссылкам, которые будут появляться в `output` выполнения ML Конвейра, чтобы проследить за статусом исполнения._\n",
    "\n",
    "## Результат\n",
    "\n",
    "Получим список всех зарегистрированных ML моделей и найдем модель, обученную в этом Эксперименте: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-predict-model v3\n",
      "\t Lab : 5A\n",
      "diabetes-predict-model v2\n",
      "\t Lab : 5B\n",
      "\t AUC : 0.8576173518134779\n",
      "\t Accuracy : 0.787\n",
      "diabetes-predict-model v1\n",
      "\t Lab : 4B\n",
      "\t AUC : 0.8576982541474856\n",
      "\t Accuracy : 0.7876666666666666\n"
     ]
    }
   ],
   "source": [
    "for model in Model.list(ws):\n",
    "    print(f'{model.name} v{model.version}')\n",
    "    \n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t', tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t', prop_name, ':', prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это простой пример, призванный продемонстрировать принцип. На самом деле вы можете встроить более сложную логику в этапы конвейера - например, оценить модель по некоторым тестовым данным, чтобы вычислить метрику производительности, такую как AUC или точность, сравнить метрику с метрикой любых ранее зарегистрированных версий модели и зарегистрировать новую модель только в том случае, если она работает лучше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
