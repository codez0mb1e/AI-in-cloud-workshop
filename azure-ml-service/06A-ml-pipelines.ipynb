{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Pipelines\n",
    "\n",
    "Цель лабораторной работы: \n",
    "\n",
    "- создание с __Конвейеров машинного обучения__ (ML Pipelines) в Azure ML\n",
    "- тренировка модели машинного обучения.\n",
    "\n",
    "## Подготовка \n",
    "\n",
    "Импорт необходимых модулей и проверка версии AzureML SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Environment, Experiment, Model\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "# Check core SDK version number\n",
    "print(f'SDK version: {azureml.core.VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры Эксперимента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ml_pipeline_demo'\n",
    "\n",
    "experiment_dir = 'ml-pipeline-demo'\n",
    "os.makedirs(experiment_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Соединение со Azure ML Workspace\n",
    "\n",
    "Устанавливаем соединение с Рабочей областью в Azure ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(f'Successfully connected to Workspace: {ws.name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зададим Шаги ML Конвейера\n",
    "\n",
    "Зададим и сохраним скрипт для Шага регистрации модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/register-model.py\n",
    "\n",
    "#%% Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "\n",
    "#%% Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir', type=str, dest='model_dir', default='outputs', help='Define ML model directory')\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "#%% Set model directory\n",
    "model_dir = args.model_dir\n",
    "\n",
    "\n",
    "#%% Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "#%% Load the model\n",
    "model_path = f'{model_dir}/model.pkl'\n",
    "\n",
    "print(f'Loading {model_path}...')\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "#%% Register model\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path=model_path,\n",
    "               model_name='diabetes_predict_model',\n",
    "               tags={'Demo': 'ML Pipeline'})\n",
    "\n",
    "#%% Finish Experiment\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим и запустим ML Конвейер\n",
    "\n",
    "Подготовка к созданию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "data_ds = ws.datasets.get('diabetes_db')\n",
    "print(f'Used dataset {data_ds.name}: {data_ds.description}')\n",
    "\n",
    "# Get environment\n",
    "env = Environment.get(ws, 'diabetes-experiment-env')\n",
    "print(f'Environment {env.name} will be used.')\n",
    "\n",
    "# Get compute cluster\n",
    "cluster = ComputeTarget(workspace=ws, name='ml-cluster')\n",
    "cluster_state = cluster.get_status()\n",
    "print(f'ML cluster contains {cluster_state.current_node_count} compute nodes in {cluster_state.allocation_state} state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируем необходимые скрипты в директорию Эксперимента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp scripts/train-model.py $experiment_dir\n",
    "!cp scripts/register-model.py $experiment_dir\n",
    "!ls $experiment_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение Шагов ML Конвейера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages related with Azure ML Pipeline \n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "\n",
    "## Step 0: Prepare\n",
    "# Set Pipeline Run Configuration\n",
    "pipeline_run_config = RunConfiguration()\n",
    "pipeline_run_config.target = cluster\n",
    "pipeline_run_config.environment = env\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_dir = PipelineData('model_dir', datastore=ws.get_default_datastore())\n",
    "\n",
    "\n",
    "## Step 1: Train model\n",
    "estimator = SKLearn(source_directory=experiment_dir,\n",
    "                    compute_target=cluster,\n",
    "                    environment_definition=pipeline_run_config.environment,\n",
    "                    entry_script='train-model.py')\n",
    "\n",
    "\n",
    "train_model_step = EstimatorStep(name='Train Model Step',\n",
    "                                 estimator=estimator, \n",
    "                                 estimator_entry_script_arguments=['--output_dir', model_dir],\n",
    "                                 inputs=[data_ds.as_named_input('data')],\n",
    "                                 outputs=[model_dir],\n",
    "                                 compute_target=cluster,\n",
    "                                 allow_reuse=True)\n",
    "\n",
    "## Step 2: Register trained model\n",
    "register_model_step = PythonScriptStep(name='Register Model Step',\n",
    "                                       source_directory=experiment_dir,\n",
    "                                       script_name='register-model.py',\n",
    "                                       arguments=['--model_dir', model_dir],\n",
    "                                       inputs=[model_dir],\n",
    "                                       compute_target=cluster,\n",
    "                                       runconfig=pipeline_run_config,\n",
    "                                       allow_reuse=True)\n",
    "\n",
    "## Complete\n",
    "print('Pipeline steps were completely defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск созданного ML-конвейера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the pipeline\n",
    "pipeline_steps = [train_model_step, register_model_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline was built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name=experiment_name\n",
    "                       )\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Перейдети по ссылкам, которые будут появляться в `output` выполнения ML Конвейра, чтобы проследить за статусом исполнения._\n",
    "\n",
    "Получим список всех зарегистрированных ML моделей и найдем модель, обученную в этом Эксперименте: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in Model.list(ws):\n",
    "    print(f'{model.name} v{model.version}')\n",
    "    \n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t', tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t', prop_name, ':', prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это простой пример, призванный продемонстрировать принцип. На самом деле вы можете встроить более сложную логику в этапы конвейера - например, оценить модель по некоторым тестовым данным, чтобы вычислить метрику производительности, такую как AUC или точность, сравнить метрику с метрикой любых ранее зарегистрированных версий модели и зарегистрировать новую модель только в том случае, если она работает лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "## Полезные ссылки\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
